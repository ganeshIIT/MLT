{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as lg\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Polynomial regression**\n",
    "\n",
    "This colab implements polynomial regression from scratch with basic python libraties like `numpy`. Recall that polynomial regression is linear regression wtih  an additional step of polynomial transformation.\n",
    "    \n",
    "                            Features --> polynomial transformation --> Linear regression --> Label\n",
    "we will use `LinReg` class that implements linear regression model.\n",
    "We will implement:\n",
    "* Polynomial transformation function.\n",
    "\n",
    "* Function for generation of training data with non-linear relationship between features and labels. We generate examples with single features $x_1$ and label $y$.\n",
    "* Also a function for visualization of training data and model fitting.\n",
    "\n",
    "We use polynomial transformations of different degress for modelling relationship between input features and labels. Each degree results in a new polynomial model. \n",
    "\n",
    "Thus, we have multiple polynomial models from which we need to select the best performing model. Implementation of the model selection scheme is performed at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the implementation of different components of Linear Regression that we implemented so far into a single `LinearRegression` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg(object):\n",
    "    '''\n",
    "    Linear regression model \n",
    "    -----------------------\n",
    "    y = X@w \n",
    "    X : A feature matrix \n",
    "    w : weight vector\n",
    "    y : label vector\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t0 = 200\n",
    "        self.t1 = 100_000\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Prediction of output label for a given input.\n",
    "\n",
    "        Args: \n",
    "        X: Feature matrix for given inputs.\n",
    "        \n",
    "        Returns:\n",
    "        y: Output label vector as predicted by the given model\n",
    "\n",
    "        '''\n",
    "        y = X@self.w\n",
    "        return y\n",
    "\n",
    "    def loss(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        ''' \n",
    "        Calculates loss for a model based on known labels:\n",
    "\n",
    "        Args: \n",
    "        X: Feature matrix for given inputs.\n",
    "        Returns:\n",
    "        y: Output label vector as predicted by the given model\n",
    "        \n",
    "        Returns:\n",
    "        y: Output label vector as predicted by the given model\n",
    "\n",
    "        '''\n",
    "        e = self.predict(X) - y\n",
    "\n",
    "        return (1/2) * (np.transpose(e)@e)\n",
    "\n",
    "    def rmse(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "\n",
    "        '''\n",
    "        Calculates root mean squared error of prediction w.r.t. actual label:\n",
    "\n",
    "        Args: \n",
    "        X: Feature matrix for given inputs.\n",
    "        Returns:\n",
    "        y: Output label vector as predicted by the given model\n",
    "        \n",
    "        Returns:\n",
    "        rmse \n",
    "\n",
    "        '''\n",
    "        return np.sqrt(2/X.shape[0] * self.loss(X, y))\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        '''' \n",
    "        Estimates parameters of the linear regression model with normal equation.\n",
    "\n",
    "        Args:\n",
    "        X: Feature matrix for given inputs \n",
    "        y: output label vector as predicted by the given model\n",
    "\n",
    "        Returns:\n",
    "        weight vector \n",
    "\n",
    "        '''\n",
    "        self.w = np.linalg.pinv(X)@y\n",
    "\n",
    "    def calculate_gradient(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        ''' \n",
    "        calculates gradients of loss function w.r.t weight vector on training set.\n",
    "\n",
    "        Returns:\n",
    "        A vector of gradient .\n",
    "        '''\n",
    "\n",
    "        return np.transpose(X)@(self.predict(X)-y)\n",
    "\n",
    "    def update_weight(self, grad: np.ndarray, lr: float) -> np.ndarray:\n",
    "        return(self.w - lr*grad)\n",
    "\n",
    "    def learning_schedule(self, t):\n",
    "        return self.t0/(t+self.t1)\n",
    "\n",
    "    def gd(self, X: np.ndarray, y: np.ndarray, num_epochs: int, lr: float) -> np.ndarray:\n",
    "        self.w = np.zeros(X.shape[1])\n",
    "        self.w_all = []\n",
    "        self.err_all = []\n",
    "        for i in np.arange(0, num_epochs):\n",
    "            djdw = self.calculate_gradient(X, y)\n",
    "            self.w_all.append(w)\n",
    "            self.err_all.append(self.loss(X, y))\n",
    "            self.w = self.update_weights(djdw, lr)\n",
    "        return self.w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Polynomial transformation**\n",
    "\n",
    "Steps for generating polynomial transformation of degree *M*.\n",
    "1. Generate combination of input features of lengths $= 0,1,\\ldots, \\textit M.$\n",
    "2. Perform multiplication operation between features to obtain the new features.\n",
    "\n",
    "\n",
    "For example:\n",
    "* For a single feature $x_1$ , $ \\phi_m = [1,x_1^1,x_1^2, \\ldots , x_1^m]$\n",
    "\n",
    "  * Generate combinations of : $\\{1,x_1,(x_1,x_1), (x_1,x_1,x_1),\\ldots, (x_1,x_1), \\ldots, (m times)\\}$\n",
    "\n",
    "    * 0-th degree: 1\n",
    "\n",
    "    * 1st degree: $x_1$\n",
    "\n",
    "    * 2nd degree: $x_1,x_1$\n",
    "\n",
    "    * 3rd degree: $x_1,x_1,x_1$\n",
    "\n",
    "    * mth degree:$(x_1,x_1,x_1,\\ldots ,m \\ times)$\n",
    "\n",
    "  * Taking the product of elements in combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "import functools \n",
    "\n",
    "def get_combinations(X, degree):\n",
    "    return itertools.combinations_with_replacement(X,degree)\n",
    "\n",
    "def compute_new_feature(items):\n",
    "    return functools.reduce(lambda x ,y : x*y , items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "char_lst = []\n",
    "for i in range(0, 4):\n",
    "    a = (get_combinations(['a', 'b'], i))\n",
    "\n",
    "    #print((tuple(a)))\n",
    "\n",
    "for tuple in a:\n",
    "    temp = ''\n",
    "    for char in tuple:\n",
    "        temp += char\n",
    "    char_lst.append(temp)\n",
    "\n",
    "print(len(char_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({item: compute_new_feature(item) for item in get_combinations([1,2,3,4,5],4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1 2 3 4 5]\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(x.ndim)\n",
    "print(x)\n",
    "\n",
    "if x.ndim == 1:\n",
    "    x = x[:, None]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([np.ones(4)])\n",
    "features = features[:, None]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  8.,  1.,  8., 64.],\n",
       "       [ 1.,  5.,  2., 25., 10.,  4.],\n",
       "       [ 1.,  2.,  0.,  4.,  0.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def polynomial_transform(x,degree):\n",
    "    if x.ndim ==1:\n",
    "        x=x[:, None]\n",
    "    x_t = x.transpose()\n",
    "    features = [np.ones(len(x))]\n",
    "    for degree in range(1, degree+1):\n",
    "        for items in itertools.combinations_with_replacement(x_t ,degree):\n",
    "            features.append(functools.reduce(lambda x ,y : x*y , items)) \n",
    "    return np.asarray(features).transpose() \n",
    "\n",
    "polynomial_transform(np.array([[1,8],[5,2],[2,0]]),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a non-linear training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nonlinear_training_set(func, sample_size, std):\n",
    "    x = np.linspace(0, 1, sample_size)\n",
    "    y = func(x) + np.random.normal(scale=std, size=x.shape)\n",
    "    return x, y\n",
    "\n",
    "def nonlin(x):\n",
    "    return np.sin(2*np.pi*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = create_nonlinear_training_set(nonlin, 50, 0.1)\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining different components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_transform(x, degree):\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, None]\n",
    "    x_t = x.transpose()\n",
    "    features = [np.ones(len(x))]\n",
    "    for degree in range(1, degree+1):\n",
    "        for items in itertools.combinations_with_replacement(x_t, degree):\n",
    "            features.append(functools.reduce(lambda x, y: x*y, items))\n",
    "    return np.asarray(features).transpose()\n",
    "\n",
    "def coef(X, y):\n",
    "    return np.linalg.pinv(X)@y\n",
    "\n",
    "def model_error(X, y, degree):\n",
    "    X_transformed = polynomial_transform(X, degree)\n",
    "    w = coef(X_transformed, y)\n",
    "    e = X_transformed@w - y\n",
    "    return np.sqrt(1/X_transformed.shape[0] * e.T@e)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32f02dc107888b055323539767db1f9cf579f03b0ed3a3ace7986ed2d38433ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
