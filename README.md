##  Machine-Learning Techniques

___
### Course structure


[WEEK 2](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W2%20-%20Linear%20Regression) - 	Models of regression; Linear regression - least squares; Polynomial regression - learning curves; Regularized linear models - Ridge, LASSO

[WEEK 3](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W3%20-%20Polynomial%20Regression) - 	Models of regression; Linear regression - least squares; [Polynomial regression](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W3%20-%20Polynomial%20Regression) - learning curves; Regularized linear models - Ridge, LASSO

[WEEK 4](https://github.com/faizanxmulla/machine-learning-techniques) - 	Models of classification ; Discriminant functions and decision boundaries - two classes, multiple classes, [least squares](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W4%20-%20Least%20Square%20Classification), [perceptron](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W4%20-%20Perceptron); Probabilistic generative and discriminative models - ML, Naive Bayes, exponential family, logistic regression

[WEEK 5](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W5%20-%20Logistic%20Regression) - 	Models of classification ; Discriminant functions and decision boundaries - two classes, multiple classes, least squares, perceptron; Probabilistic generative and discriminative models - ML, Naive Bayes, exponential family, [logistic regression](https://github.com/faizanxmulla/machine-learning-techniques/blob/main/W5%20-%20Logistic%20Regression/1LoR.ipynb)

[WEEK 6](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W6%20-%20Naive%20Bayes) - 	Models of classification ; Discriminant functions and decision boundaries - two classes, multiple classes, least squares, perceptron; Probabilistic generative and discriminative models - ML, [Naive Bayes](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W6%20-%20Naive%20Bayes), exponential family, logistic regression

[WEEK 7](https://github.com/faizanxmulla/machine-learning-techniques) - 	Models of classification ; [Softmax regression](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W7%20-%20Softmax%20Regression) ; [k-NN](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W7%20-%20KNN) - regression and classification problems

[WEEK 8](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W8%20-%20SVM) - 	Support Vector Machines; Linear SVM - soft margin classification; Nonlinear SVM - kernels

[WEEK 9](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W9%20-%20Decision%20Trees) - 	Decision Trees; Training decision trees, making predictions;

[WEEK 10](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W10%20-%20Ensemble%20-%20Random%20Forest) - 	Ensemble Methods and Random Forests; Bagging, Boosting;

[WEEK 11](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W11%20-%20KMeans) - 	Clustering; KMeans - algorithm, demo and how to select k-HAC

[WEEK 12](https://github.com/faizanxmulla/machine-learning-techniques/tree/main/W12%20-%20Neural%20Networks) - 	Neural networks; Multi-layer perceptron, activation functions; Training - SGD and back propagation; Hyperparameters - number of layers, neurons, activation functions.

____

### What youâ€™ll learn



* Demonstrating in-depth understanding of machine learning algorithms - model, objective or loss function, optimization algorithm and evaluation criteria.

* Tweaking machine learning algorithms based on the outcome of experiments - what steps to take in case of underfitting and overfitting.

* Being able to choose among multiple algorithms for a given task.

* Developing an understanding of unsupervised learning techniques.
---
