{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forests** \n",
    "\n",
    "Random Forest is a **bagging** technique that **trains multiple decision trees** with **minor modification** in split criterion.\n",
    "\n",
    "![](Images/rf_dt.png)\n",
    "\n",
    "In case of decision trees, we train a single decision tree. \n",
    "\n",
    "In random forest we train multiple decision trees on different training sets obtained through bagging (aka Boostrap Agreggation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Algorithm**\n",
    "**Input**:\n",
    "\n",
    "1. The training data $D$ with shape $(n,m)$, say $D_1,D_2,\\ldots ,D_q$ with replacement from $D$.\n",
    "\n",
    "2. In each of the datasets $D_j$, select $u$ out of $m$ where $u \\le m$ features before each split and train a full decision tree $h_j(\\mathbf x)$\n",
    "\n",
    "3. The final predictor : \n",
    "\n",
    "  * For regression, an average output from $q$ regressors is assigned to the new example:\n",
    "  \n",
    "  $$ h(\\mathbf x) = \\frac {1}{q} \\sum_{j=1}^q h_j(\\mathbf x) $$\n",
    "\n",
    "  * For classification, a majority voting is taken and the class label with the maximum number of votes is assigned to the new example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementation**\n",
    "\n",
    "In order to keep the implementation focussed to main components of random forest, we make use of `DecisionTreeClassifier` from scikit-learn library for the decision tree components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build the code component-wise and finally combine them into a `RandomForest` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bagging**\n",
    "\n",
    "We define a function for bagging - creating boostrap samples $D_1,D_2,\\ldots,D_q$ from the original dataset $D:$\n",
    "\n",
    "The **key step** is : \n",
    "\n",
    "`np.random.choice` with **size=n_samples** and **replace=True** \n",
    "\n",
    "It ensures that the boostrapped sample has the same number of samples as the original dataset and it is obtained by sampling with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag(X, y):\n",
    "    # Counts the number or rows in the feature matrix\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Generates a random sample from the  given input.\n",
    "    indices = np.random.choice(n_samples, size=n_samples, replace=True, random_state=1)\n",
    "\n",
    "    # Note that the second argument size has been set to the size of the original sample dataset and replacement has been set to True\n",
    "\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Majority Voting**\n",
    "Code `up` `most_common_label` function for obtaining majority vote for  class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_label(y):\n",
    "    counter = Counter(y)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 5, 2: 4, 1: 3, 0: 2})\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "y = [1, 1, 1, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3, 3]\n",
    "\n",
    "print(Counter(y))\n",
    "print(Counter(y).most_common(2)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random forest class**\n",
    "\n",
    "We create a `RandomForest` class with the following default parameters :\n",
    "\n",
    "* number of trees = 10\n",
    "\n",
    "* minimum number of samples = 2\n",
    "\n",
    "* maximum depth = 100 \n",
    "\n",
    "The `max_features` is a configurable parameter that can be set by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, min_samples_split=2, max_depth=100, max_features=None):\n",
    "        # hyperparameter for fixing number of trees to be generated\n",
    "        self.n_trees = n_trees  \n",
    "\n",
    "        # min no of samples required for split\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "        # maximum depth of decision tree\n",
    "        self.max_depth = max_depth \n",
    "\n",
    "        # maximum no of features to be considered\n",
    "        self.max_features = max_features  \n",
    "        self.trees = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Random Forest**\n",
    "We implement the `fit` method.\n",
    "\n",
    "* Initialize an empty list of decision tree classifiers.\n",
    "\n",
    "* In the `for` loop, we train each decision tree with parameters set from random forest on a boostrapped sample obtained through the `bag` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y):\n",
    "    # Empty array of trees which gets filled in during operations.\n",
    "    self.trees = []\n",
    "\n",
    "    # we are using underscore we are just repeating the operations.\n",
    "    for _ in range(self.n_trees):\n",
    "        tree = DecisionTreeClassifier(\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            max_depth=self.max_depth,\n",
    "            max_features=self.max_features)\n",
    "\n",
    "    X_sample, y_sample = bag(X, y)\n",
    "    tree.fit(X_sample, y_sample)\n",
    "    # we will append each of these tree.\n",
    "    self.trees.append(tree)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference**\n",
    "Let's implement `predict` function : \n",
    "\n",
    "Here, we need to note that each of the trees will give predictions for all the individual rows of the input data.\n",
    "\n",
    "**For example :** If we have a random forest with 3 trees and 2 classes 0 & 1, let's assume the prediciton for 5 samples is as follows : \n",
    "\n",
    "* Tree 1 gives 00111\n",
    "\n",
    "* Tree 2 gives 11001\n",
    "\n",
    "* Tree 3 gives 10101\n",
    "\n",
    "We need to aggregate the output for the respective samples and take an average / majority vote. For this, we will use `np.swapaxes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    tree_predict = np.array([tree.predict(X) for tree in self.trees])\n",
    "\n",
    "    # each of the trees will give out predictions\n",
    "    tree_predict = np.swapaxes(tree_predict, 0, 1)\n",
    "\n",
    "    y_pred = [most_common_label(tree_pred) for tree_pred in tree_predict]\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Combined all Components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag(X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "\n",
    "def most_common_label(y):\n",
    "  counter = Counter(y)\n",
    "  most_common = counter.most_common(1)[0][0]\n",
    "  return most_common\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "  def __init__(self, n_trees=10, min_samples_split=2, max_depth=100, max_features=None):\n",
    "    self.n_trees = n_trees  \n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth  \n",
    "    self.max_features = max_features \n",
    "    self.trees = []\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    self.trees = []\n",
    "\n",
    "    for _ in range(self.n_trees):\n",
    "      tree = DecisionTreeClassifier(  \n",
    "          min_samples_split=self.min_samples_split,\n",
    "          max_depth=self.max_depth,\n",
    "          max_features=self.max_features)\n",
    "\n",
    "      X_sample, y_sample = bag(X, y)\n",
    "      tree.fit(X_sample, y_sample)\n",
    "      self.trees.append(tree)  \n",
    "\n",
    "  def predict(self, X):\n",
    "    tree_predict = np.array([tree.predict(X) for tree in self.trees])\n",
    "    tree_predict = np.swapaxes(tree_predict, 0, 1)\n",
    "\n",
    "    y_pred = [most_common_label(tree_pred) for tree_pred in tree_predict]\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Demonstration**\n",
    "\n",
    "Let us demonstrate our implementation of Random Forest on a real world dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred)/len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForest(n_trees=10, max_depth=10, max_features='sqrt')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the confusion matrix and classification report on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGpCAYAAACqF70iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAetElEQVR4nO3deZRddZXo8e9OJQgiU0BiSFDwgSD6NLSI4EAzKOII2jRKKx1tNLYDCraN6HOZpW0/UbtBlkNLBDQ2MsnQ8GSQvDTIICBRBjHRBxKQzBIQEaIkufv9USexjEndqso999avzvfDOqvuOeeec3ZYZNVm79/vdyIzkSRJKsG4XgcgSZI0VCYukiSpGCYukiSpGCYukiSpGCYukiSpGON7HcCmzJt6lNOdpB7421ULex2C1FgLV94V3Xze6ofv79jv2gk7PbcrsVtxkSRJxRi1FRdJklSz1tpeRzBsJi6SJDVVtnodwbDZKpIkScWw4iJJUlO1yqu4mLhIktRQaatIkiSpPiYukiQ1VavVuW0QEbFXRNw5YPtdRJwYERMjYk5E3Fv93KFdyCYukiQ1VbY6tw32mMxfZua0zJwGvAR4ErgMOAWYm5l7AnOr/UGZuEiSpG46DPhVZj4IHAnMro7PBo5qd7GDcyVJaqoOLkAXETOAGQMOzcrMWRv56tuB86vPkzJzafV5GTCp3XNMXCRJaqoOziqqkpSNJSrrRcQWwJuBT2zk+oyItu9OslUkSZK65XXATzNzebW/PCImA1Q/V7S7gYmLJElN1aVZRQMcy5/aRABXANOrz9OBy9vdwFaRJEkN1c0F6CJia+A1wPsGHD4VuCgijgceBI5pdx8TF0mSVLvMfALYcYNjK+mfZTRkJi6SJDWV7yqSJEnF8F1FkiRJ9bHiIklSU3VwAbpuMXGRJKmpbBVJkiTVx4qLJElN5awiSZJUDFtFkiRJ9bHiIklSU9kqkiRJpcgsbzq0rSJJklQMKy6SJDVVgYNzTVwkSWoqx7hIkqRiFFhxcYyLJEkqhhUXSZKaypcsSpKkYtgqkiRJqo8VF0mSmspZRZIkqRi2iiRJkupjxUWSpKayVSRJkopRYOJiq0iSJBXDioskSQ2V6QJ0kiSpFLaKJEmS6mPFRZKkpipwHRcTF0mSmspWkSRJUn2suEiS1FS2iiRJUjFsFUmSJNXHioskSU1lq0iSJBXDVpEkSVJ9rLhIktRUBVZcTFwkSWqqAse42CqSJEnFsOIiSVJT2SqSJEnFsFUkSZJUHysukiQ1VYGtIisukiQ1VbY6t7UREdtHxMUR8YuIWBARB0bExIiYExH3Vj93aHcfExdJktQNZwDXZObewIuBBcApwNzM3BOYW+0PylaRJElN1aVWUURsBxwEvAsgM58CnoqII4GDq6/NBq4HPj7Yvay4SJLUVK1Wx7aImBER8wZsMwY8aXfgN8C3IuKOiDgrIrYGJmXm0uo7y4BJ7UK24iJJkjZbZs4CZm3i9Hjgr4ATMvO2iDiDDdpCmZkRke2eY8VFkqSmyuzcNrhFwKLMvK3av5j+RGZ5REwGqH6uaHcjExdJkpqqg62iwWTmMuChiNirOnQYMB+4ApheHZsOXN4uZFtFkiSpG04AvhsRWwD3A++mv4ByUUQcDzwIHNPuJiYukiQ1VRcXoMvMO4H9NnLqsOHcx8RFkqSm8l1FkiRJ9bHiIklSUxX4riITF0mSmqr9NOZRx1aRJEkqhhUXSZKaylaRJEkqRoGJi60iSZJUDCsukiQ1VYHruJi4SJLUUNlyVpEkSVJtrLhIktRUBQ7ONXGRJKmpChzjYqtIkiQVw4qLJElNVeDgXBMXSZKayjEukiSpGAUmLo5xkSRJxbDiIklSU6VjXCRJUilsFUmSJNXHios2SzxtAntf8q/EFhOIvj4evepHLPn3CwCYcvI72OGNLyfXtvjNf17DinOu7HG00ti2zbbb8IUzZvK85+9BZnLyCTO5Y97dvQ5Lo5nTodU0+cfV/PKYT9N68g/E+D72uuzzPHbdT9lyj6lM2GUn7vnrD0Em43fcrtehSmPezM+fzA/n3swH3v0xJkwYz5ZbbdXrkDTauXKumqj15B8AiPF9xPg+yGTnvz+CpV++cP3ArzUrH+tliNKYt802z2D/A1/ChedeBsDq1Wt4/HeP9zgqqfNqq7hExN7AkcCU6tBi4IrMXFDXM9Uj48axz9X/ztN2exYrZl/NE3fcy9Oe8ywmvumVbH/EAax55DF+/emz+OPCpb2OVBqzpj5nCo+sfJQvffWzPP8Fe3HPXfP5zCe/yKonV/U6NI1mBbaKaqm4RMTHgQuAAH5cbQGcHxGnDHLdjIiYFxHzLn3igTpCUx1aLea/9iTuful72Hranmy517OJLSbQ+uNqFrzhY/zmvDns9m8n9DpKaUwbP76PF7xob777re/xxkPexpNPruL9H/mHXoelUS5brY5t3VJXq+h44KWZeWpmnlttpwL7V+c2KjNnZeZ+mbnfW7ferabQVJe1v3uCx3/0M7Y7eF+eWrqSR6++BYDfXn0rWz3/OT2OThrbli5ZzrIly7nzJz8D4Oor5vCCF+3d46ikzqsrcWkBu2zk+OTqnMaI8RO3pW/brQGILbdg21dN4w/3Lea3P7iNbV7+PwHY5sAX8sf7l/QyTGnMe3jFSpYuXs5z9+j/n4SXH/Qy7vvl/T2OSqNeKzu3dUldY1xOBOZGxL3AQ9WxZwN7AB+q6ZnqgQmTdmD30z8CfeOICB75/s08Nncev799Abt/5SQmvffNtJ5YxQP//LVehyqNeTNPOZXTz/w8W0yYwK8fXMQ/f+jTvQ5Jo12Bs4oia1ruNyLG0d8aGjg49/bMXDuU6+dNPaq8EUPSGPC3qxb2OgSpsRauvCu6+bwnPvfOjv2u3fpT53Yl9tpmFWVmC7i1rvtLkqTNVOCsIhegkySpqXxXkSRJUn2suEiS1FS2iiRJUjEKnFVkq0iSJBXDioskSU1lq0iSJJWim+8Y6hRbRZIkqRhWXCRJaipbRZIkqRgFJi62iiRJUjGsuEiS1FQFruNi4iJJUlN1sVUUEQ8AjwNrgTWZuV9ETAQuBHYDHgCOycxHB7uPrSJJktQth2TmtMzcr9o/BZibmXsCc6v9QZm4SJLUUNnKjm0jdCQwu/o8Gziq3QW2iiRJaqruzipK4NqISODMzJwFTMrMpdX5ZcCkdjcxcZEkSZstImYAMwYcmlUlJ+u8MjMXR8TOwJyI+MXA6zMzq6RmUCYukiQ1VQeX/K+SlFmDnF9c/VwREZcB+wPLI2JyZi6NiMnAinbPcYyLJElN1crObYOIiK0jYpt1n4HDgXuAK4Dp1demA5e3C9mKiyRJqtsk4LKIgP7c47zMvCYibgcuiojjgQeBY9rdyMRFkqSm6tLg3My8H3jxRo6vBA4bzr1MXCRJaqhM31UkSZJUGysukiQ1VYFvhzZxkSSpqQpMXGwVSZKkYlhxkSSpoTbjHUM9Y+IiSVJTFZi42CqSJEnFsOIiSVJTde5VRV1j4iJJUkOVOMbFVpEkSSqGFRdJkpqqwIqLiYskSU1V4BgXW0WSJKkYVlwkSWqoEgfnmrhIktRUtookSZLqY8VFkqSGslUkSZLKUWCryMRFkqSGygITF8e4SJKkYlhxkSSpqQqsuJi4SJLUULaKJEmSamTFRZKkpiqw4mLiIklSQ9kqkiRJqpEVF0mSGqrEiouJiyRJDVVi4mKrSJIkFcOKiyRJTZXR6wiGzcRFkqSGslUkSZJUIysukiQ1VLZsFUmSpELYKpIkSaqRFRdJkhoqnVUkSZJKYatIkiSpRlZcJElqqDE1qygivgLkps5n5odriUiSJHVFbvK3/Og1WMVlXteikCRJGoJNJi6ZOXvgfkQ8PTOfrD8kSZLUDSW2itoOzo2IAyNiPvCLav/FEfH12iOTJEm1ylZ0bOuWocwq+jLwWmAlQGbeBRxUY0ySJGkMioi+iLgjIr5f7e8eEbdFxH0RcWFEbNHuHkOaDp2ZD21waO0I4pUkSaNIZue2IfoIsGDA/heA0zNzD+BR4Ph2NxhK4vJQRLwcyIiYEBEf2+ChkiSpQN1sFUXEVOANwFnVfgCHAhdXX5kNHNXuPkNJXP4R+CAwBVgCTKv2JUmSAIiIGRExb8A2Y4OvfBk4GVi3Xu+OwG8zc021v4j+XGNQbRegy8yHgXcMOXJJklSETr6rKDNnAbM2di4i3gisyMyfRMTBm/OctolLRDwXOAM4gP4F6W4BTsrM+zfnwZIkqbe6+K6iVwBvjojXA1sC29KfW2wfEeOrqstUYHG7Gw2lVXQecBEwGdgF+B5w/ggDlyRJDZOZn8jMqZm5G/B24L8z8x3AdcDR1demA5e3u9dQEpenZ+Z/ZuaaajuX/mxJkiQVrJXRsW2EPg58NCLuo3/My9ntLhjsXUUTq49XR8QpwAX0t4reBlw10gglSdLo0MkxLkN/Zl4PXF99vh/YfzjXDzbG5Sf0Jyrr/lTvG/hc4BPDeZAkSdLmGuxdRbt3MxBJktRdJb6rqO2sIoCIeCGwDwPGtmTmd+oKSpIk1W8YK96OGkOZDj0TOJj+xOUq4HXATYCJiyRJ6qqhVFyOBl4M3JGZ746IScC59YYlSZLqNlZbRasysxURayJiW2AFsGvNcUmSpJptxjTmnhlK4jIvIrYHvkn/TKPf0796riRJUlcN5V1FH6g+fiMirqF/md6Ha41KkiTVrhfruGyuIc0qWiczHwCIiF8Dz64jIEmS1B0lzioaypL/G1NeiiZJkoo3rIrLAAXmaJIkaaAxNTg3Ir7CxhOUALavKyBJktQdY22My7wRnpMkSarFYO8qmt3NQCRJUneVODh3pGNcJElS4Uoc4zLSWUWSJEldN2orLgesuL3XIUiNtGrJjb0OQVKXjKnBuYPMKgIgMz9cS0SSJKkrSmwVjXRWkSRJUtc5q0iSpIYqcFJR+zEuEfFM4OPAPsCW645n5qE1xiVJkmpWYqtoKLOKvgssAHYHPgM8ADhyVpKkwmVGx7ZuGUrismNmng2szswfZuY/AFZbJElS1w1lOvTq6ufSiHgDsASYWF9IkiSpG1q9DmAEhpK4fC4itgP+CfgKsC1wUq1RSZKk2iXljXFpm7hk5verj48Bh9QbjiRJ0qYNZVbRt9jIjKlqrIskSSpUq8D50ENpFX1/wOctgbfQP85FkiQVrDVGW0WXDNyPiPOBm2qLSJIkaRNG8pLFPYGdOx2IJEnqrjE5ODciHufPx7gso38lXUmSVLAxOR06M7fpRiCSJEnttF05NyLmDuWYJEkqSxId27plkxWXiNgSeDqwU0TsAOuj2haY0oXYJElSjcZaq+h9wInALsBP+FPi8jvgq/WGJUmS9Jc2mbhk5hnAGRFxQmZ+pYsxSZKkLiix4jKUt0O3ImL7dTsRsUNEfKC+kCRJUjeUOMZlKInLezPzt+t2MvNR4L21RSRJkrQJQ1mAri8iIjMTICL6gC3qDUuSJNWtVd76c0NKXK4BLoyIM6v991XHJElSwcbku4roXyV3BvD+an8O8M3aIpIkSdqEtmNcMrOVmd/IzKMz82hgPuAsI0mSCpcd3LplSC9ZjIh9gWOBY4CFwKV1BiVJkupX4nTowVbOfR79ycqxwMPAhUBk5iFdik2SJOnPDFZx+QVwI/DGzLwPICJO6kpUkiSpdq3ozuDc6jVCNwBPoz/3uDgzZ0bE7sAFwI70r9J/XGY+Ndi9Bhvj8lZgKXBdRHwzIg6DAocfS5KkjeriGJc/Aodm5ouBacAREXEA8AXg9MzcA3gUOL7djTaZuGTmf2Xm24G9gevof2/RzhHxHxFxePsYJUmSIPv9vtqdUG0JHApcXB2fDRzV7l5DmVX0RGael5lvAqYCd9A/RVqSJBWs1cEtImZExLwB24yBz4qIvoi4E1hB/9IqvwJ+m5lrqq8sAqa0i3lIs4rWqZb7n1VtkiSpYJ1cOTczB80PMnMtMK16/+Fl9Hd0hm0o7yqSJEnqiOr9h9cBBwLbR8S6IspUYHG7601cJElqqBbRsW0wEfHMqtJCRGwFvAZYQH8Cc3T1tenA5e1iHlarSJIkjR1dXPF2MjC7elHzOOCizPx+RMwHLoiIz9E/hvbsdjcycZEkSbXKzLuBfTdy/H5g/+Hcy8RFkqSG6uTg3G4xcZEkqaFKfFeRg3MlSVIxrLhIktRQXRyc2zEmLpIkNVSJY1xsFUmSpGJYcZEkqaFKHJxr4iJJUkOVmLjYKpIkScWw4iJJUkNlgYNzTVwkSWooW0WSJEk1suIiSVJDlVhxMXGRJKmhSlw511aRJEkqhhUXSZIaqsQl/01cJElqqBLHuNgqkiRJxbDiIklSQ5VYcTFxkSSpoZxVJEmSVCMrLpIkNZSziiRJUjEc4yJJkorhGBdJkqQaWXGRJKmhWgXWXExcJElqqBLHuNgqkiRJxbDiIklSQ5XXKDJxkSSpsWwVSZIk1ciKiyRJDeXKuZIkqRglToe2VSRJkophxUWSpIYqr95i4iJJUmM5q0iSJKlGVlwkSWqoEgfnmrhIktRQ5aUttookSVJBrLhIktRQJQ7ONXGRJKmhShzjYqtIkiQVw4qLJEkNVV69xYqLJEmN1ergNpiI2DUirouI+RHx84j4SHV8YkTMiYh7q587tIvZxEWSJNVtDfBPmbkPcADwwYjYBzgFmJuZewJzq/1BmbhIktRQ2cF/Bn1O5tLM/Gn1+XFgATAFOBKYXX1tNnBUu5hNXCRJaqhOtooiYkZEzBuwzdjYMyNiN2Bf4DZgUmYurU4tAya1i9nBuZIkabNl5ixg1mDfiYhnAJcAJ2bm7yJi4PUZEW3HC5u4SJLUUN1cxyUiJtCftHw3My+tDi+PiMmZuTQiJgMr2t3HVpEkSQ2VHdwGE/2llbOBBZl52oBTVwDTq8/TgcvbxWzFRZIk1e0VwHHAzyLizurYJ4FTgYsi4njgQeCYdjcycZEkqaG61SrKzJuA2MTpw4ZzLxMXSZIaypcsqvFee/jBnHbaZ+kbN45zvnU+X/zS13odkjQmLXxwER/79OfX7y9aspQPvec4lv9mJT+8+TbGTxjPrlMm87lPfpRtt3lGDyOVOisyR+ebCsZvMWV0BqZNGjduHAt+fiNHvP5YFi1ayq23XMU7j/sACxbc2+vQNAyrltzY6xA0TGvXruXQo47j/G+ezsIHF/Gyl0xj/Pg+Tvv62QB89APH9zhCDdWEnZ67qXZKLd6z29Ed+1171gMXdyV2ZxWpY/Z/6b786lcPsHDhr1m9ejUXXXQ5b37Ta3sdljTm3TrvTnadMpldnjWJV7zsJYwf3wfAi16wN8tXPNzj6DSadetdRZ1k4qKO2WXKs3ho0ZL1+4sWL2WXXZ7Vw4ikZrh67g95/av/+i+OX3bltbzywJf2ICKpPl1PXCLi3YOcW79ccKv1RDfDkqQirV69mutvuo3DD33Vnx0/c/b59PX18cbDD+lRZCpBt95V1Em9qLh8ZlMnMnNWZu6XmfuNG7d1N2NSByxZvIxdp+6yfn/qlMksWbKshxFJY9+Nt87j+c/7H+w0cYf1x/7ryjnccPOP+cLMkxm4pLq0oRJbRbXMKoqIuzd1iiG8QEllun3eneyxx+7sttuuLF68jGOOOZLj/v6DvQ5LGtOumnM9r3/Nwev3b7p1Huec9z2+/dUvstWWW/YuMKkmdU2HngS8Fnh0g+MB/KimZ6rH1q5dy0dO/BRXXXkefePG8e3ZFzJ//v/rdVjSmPXkqj9wy+13MPPkD68/9q+nfZ2nVq/mvSf+L6B/gO7Mk0/oVYga5VqjdGbxYGqZDh0RZwPfqlbK2/DceZn5d+3u4XRoqTecDi31TrenQ7/zOW/t2O/acx+8tCux11JxycxNLhowlKRFkiRpY1w5V5KkhurWu4o6ycRFkqSG6uY05k5xATpJklQMKy6SJDWUb4eWJEnFKHGMi60iSZJUDCsukiQ1VImDc01cJElqqBLHuNgqkiRJxbDiIklSQ9Xx2p+6mbhIktRQziqSJEmqkRUXSZIaqsTBuSYukiQ1lNOhJUlSMRzjIkmSVCMrLpIkNZTToSVJUjFKHJxrq0iSJBXDioskSQ3lrCJJklQMZxVJkiTVyIqLJEkN5awiSZJUDFtFkiRJNbLiIklSQzmrSJIkFaNV4BgXW0WSJKkYVlwkSWqo8uotJi6SJDWWs4okSZJqZMVFkqSGKrHiYuIiSVJDlbhyrq0iSZJUu4g4JyJWRMQ9A45NjIg5EXFv9XOHdvcxcZEkqaFaZMe2Ifg2cMQGx04B5mbmnsDcan9QJi6SJDVUdvCfts/KvAF4ZIPDRwKzq8+zgaPa3cfERZIkbbaImBER8wZsM4Zw2aTMXFp9XgZManeBg3MlSWqoTg7OzcxZwKzNuD4jom1AJi6SJDXUKJgOvTwiJmfm0oiYDKxod4GtIkmS1CtXANOrz9OBy9tdYMVFkqSG6uY6LhFxPnAwsFNELAJmAqcCF0XE8cCDwDHt7mPiIklSQ3WzVZSZx27i1GHDuY+tIkmSVAwrLpIkNdRQ1l8ZbUxcJElqqJbvKpIkSaqPFRdJkhrKVpEkSSqGrSJJkqQaWXGRJKmhbBVJkqRi2CqSJEmqkRUXSZIaylaRJEkqhq0iSZKkGllxkSSpoWwVSZKkYmS2eh3CsNkqkiRJxbDiIklSQ7VsFUmSpFKks4okSZLqY8VFkqSGslUkSZKKYatIkiSpRlZcJElqqBKX/DdxkSSpoUpcOddWkSRJKoYVF0mSGqrEwbkmLpIkNZTToSVJUjFKrLg4xkWSJBXDioskSQ3ldGhJklQMW0WSJEk1suIiSVJDOatIkiQVw1aRJElSjay4SJLUUM4qkiRJxfAli5IkSTWy4iJJUkPZKpIkScVwVpEkSVKNrLhIktRQJQ7ONXGRJKmhbBVJkiTVyMRFkqSGysyObe1ExBER8cuIuC8iThlpzCYukiQ1VHZwG0xE9AFfA14H7AMcGxH7jCRmExdJklS3/YH7MvP+zHwKuAA4ciQ3GrWDc9c8tTh6HYNGLiJmZOasXschNY1/9zQcnfxdGxEzgBkDDs0a8N/iFOChAecWAS8byXOsuKguM9p/RVIN/LunnsjMWZm534CtlgTaxEWSJNVtMbDrgP2p1bFhM3GRJEl1ux3YMyJ2j4gtgLcDV4zkRqN2jIuKZ49d6g3/7mnUycw1EfEh4AdAH3BOZv58JPeKElfNkyRJzWSrSJIkFcPERZIkFcPERR3VqSWdJQ1PRJwTESsi4p5exyLVycRFHdPJJZ0lDdu3gSN6HYRUNxMXdVLHlnSWNDyZeQPwSK/jkOpm4qJO2tiSzlN6FIskaQwycZEkScUwcVEndWxJZ0mSNsbERZ3UsSWdJUnaGBMXdUxmrgHWLem8ALhopEs6SxqeiDgfuAXYKyIWRcTxvY5JqoNL/kuSpGJYcZEkScUwcZEkScUwcZEkScUwcZEkScUwcZEkScUwcZF6KCLWRsSdEXFPRHwvIp6+Gff6dkQcXX0+a7AXXEbEwRHx8hE844GI2Gmoxzdxj3dFxFc78VxJzWPiIvXWqsyclpkvBJ4C/nHgyYgYP5KbZuZ7MnP+IF85GBh24iJJvWbiIo0eNwJ7VNWQGyPiCmB+RPRFxJci4vaIuDsi3gcQ/b4aEb+MiP8L7LzuRhFxfUTsV30+IiJ+GhF3RcTciNiN/gTppKra86qIeGZEXFI94/aIeEV17Y4RcW1E/DwizgJiqH+YiNg/Im6JiDsi4kcRsdeA07tWMd4bETMHXPPOiPhxFdeZEdE38n+dksaiEf3fnKTOqiorrwOuqQ79FfDCzFwYETOAxzLzpRHxNODmiLgW2BfYC9gHmATMB87Z4L7PBL4JHFTda2JmPhIR3wB+n5n/Vn3vPOD0zLwpIp5N/+rHzwdmAjdl5mcj4g3AcFZj/QXwqsxcExGvBv438DfVuf2BFwJPArdHxJXAE8DbgFdk5uqI+DrwDuA7w3impDHOxEXqra0i4s7q843A2fS3cH6cmQur44cDL1o3fgXYDtgTOAg4PzPXAksi4r83cv8DgBvW3SszH9lEHK8G9olYX1DZNiKeUT3jrdW1V0bEo8P4s20HzI6IPYEEJgw4NyczVwJExKXAK4E1wEvoT2QAtgJWDON5khrAxEXqrVWZOW3ggeqX9hMDDwEnZOYPNvje6zsYxzjggMz8w0ZiGal/Aa7LzLdU7anrB5zb8F0jSf+fc3ZmfmJzHippbHOMizT6/QB4f0RMAIiI50XE1sANwNuqMTCTgUM2cu2twEERsXt17cTq+OPANgO+dy1wwrqdiJhWfbwB+Lvq2OuAHYYR93bA4urzuzY495qImBgRWwFHATcDc4GjI2LndbFGxHOG8TxJDWDiIo1+Z9E/fuWnEXEPcCb91dLLgHurc9+h/83AfyYzfwPMAC6NiLuAC6tT/wd4y7rBucCHgf2qwb/z+dPsps/Qn/j8nP6W0a8HifPu6q3EiyLiNOCLwOcj4g7+srr7Y+AS4G7gksycV82C+hRwbUTcDcwBJg/x35GkhvDt0JIkqRhWXCRJUjFMXCRJUjFMXCRJUjFMXCRJUjFMXCRJUjFMXCRJUjFMXCRJUjH+P3aoImWOOWTNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        42\n",
      "           1       0.92      1.00      0.96        72\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32f02dc107888b055323539767db1f9cf579f03b0ed3a3ace7986ed2d38433ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
