{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported for proper rendering of latex in colab.\n",
    "from IPython.display import display, Math, Latex\n",
    "import numpy as np\n",
    "\n",
    "# Import for generating plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N2 : Model\n",
    "\n",
    "##### a. Quick recap\n",
    "1. Training data contains features and label that is real number.\n",
    "\n",
    "2. Linear regression model uses linear combination of features to obtain labels. In vectorized form, this can be written as $\\textbf y = \\textbf {Xw}$\n",
    "\n",
    "##### b. Objective\n",
    "The objective of this notebook is to implement model and the inference component from linear regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :**\n",
    "* Model is parameterized by its weight vector.\n",
    "\n",
    "* It is described by its mathematical form and weight vector.\n",
    "\n",
    "#### **Implementation**\n",
    "\n",
    "The general vectorized form is as follows:\n",
    "\\begin{equation} \n",
    "\\textbf y_{n\\times 1} =\\textbf X_{n \\times (m+1)} \\textbf w_{(m+1)\\times 1}\n",
    "\\end{equation}\n",
    "\n",
    "    where : \n",
    "* **n** is number of examples in dataset (train/test/validation).\n",
    "\n",
    "* **m** is the number of features.\n",
    "\n",
    "* **X** is a feature matrix contain $(m+1)$ features for $n$ examples along rows. (Notice capital case bold **X** used for matrix)\n",
    "\n",
    "* **w** is weight vector containg $(m+1)$ weights one for each feature. (notice small case bold **w**)\n",
    "\n",
    "* **y** is a label vector containing labels for $n$ examples with shape $(n,)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    assert X.shape[-1] == w.shape[0], \"X and w don't have compatible dimensions\"\n",
    "    # returns the predicted_label vector\n",
    "    return X @ w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test this function with the following feature matrix $\\textbf X_{2\\times (3+1)}:$\n",
    "\n",
    "\\begin{equation} \n",
    "\\textbf X_{2 \\times (3+1)} = \\begin{bmatrix} \n",
    "1&3&2&5\\\\ \n",
    "1&9&4&7\\end{bmatrix} \n",
    "\\end{equation}\n",
    "and weight vector $\\textbf w$ :\n",
    "\\begin{equation} \n",
    "\\textbf w_{4\\times 1}= \\begin{bmatrix}1\\\\1\\\\1\\\\1 \\end{bmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "Let's perform matrix-vector multiplication between the feature matrix $\\textbf X$ and a weight vector $\\textbf w$ to obtain labels for all examples:\n",
    "\\begin{align}\n",
    "\\textbf y&=& \\textbf {Xw}\n",
    "\\end{align} \n",
    "\n",
    "\\begin{align}\n",
    "\\\\&=& \\begin{bmatrix} 1&3&2&5\\\\ 1&9&4&7 \\end{bmatrix} \\times \\begin{bmatrix} 1\\\\1\\\\1\\\\1 \\end{bmatrix}\\\\\n",
    "\\end{align} \n",
    "\n",
    "\\begin{align}\n",
    "&=& \\begin{bmatrix} 1\\times 1+3 \\times1 +2\\times1+5\\times1 \\\\ 1\\times1 + 3\\times1 + 2\\times1 +5\\times1 \\end{bmatrix} \n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\\\ &=& \\begin{bmatrix} 11\\\\21 \\end{bmatrix} \n",
    "\\end{align} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_predict (__main__.TestPredict) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1e70ba74100>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "class TestPredict(unittest.TestCase):\n",
    "    '''Test case predict frunciton of linear regression'''\n",
    "    def test_predict(self):\n",
    "    #set up \n",
    "        train_matrix = np.array([[1,3,2,5],[1,9,4,7]])\n",
    "        weight_vector =np.array([1,1,1,1])\n",
    "        expected_label_vector=np.array([11,21])\n",
    "\n",
    "        # call\n",
    "        predicted_label_vector = predict(train_matrix,weight_vector)\n",
    "\n",
    "        # asserts\n",
    "        # test the shape\n",
    "        self.assertEqual(predicted_label_vector.shape, (2,))\n",
    "        \n",
    "        # and contents\n",
    "        np.testing.assert_array_equal(expected_label_vector,predicted_label_vector) \n",
    "\n",
    "unittest.main(argv=[''],defaultTest='TestPredict',verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration on synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummy_feature(X):\n",
    "    return np.column_stack((np.ones(X.shape[0]) ,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "w = np.array([5,6])\n",
    "X = 10*np.random.rand(100)\n",
    "X = add_dummy_feature(X)\n",
    "noise = np.random.rand(n,)\n",
    "y = X@w + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         8.26291599]\n",
      " [1.         6.3233168 ]\n",
      " [1.         4.24764423]\n",
      " [1.         9.56568747]\n",
      " [1.         0.70380504]] [54.7493043  43.4791561  31.03635453 62.53363381  9.77963824]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5],y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Dummy feature and train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have not yet trained out model, let's use random weight vector to get predictions from out model for the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31607789, 0.52993199])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_model = np.random.rand(2,)\n",
    "wt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels are:\n",
      " [3.01953067 2.0224964  0.33416342 5.00302977 1.92563714 4.86362332\n",
      " 0.87135491 5.11689399 4.8810301  4.71712963]\n",
      "\n",
      "Actual Labels are:\n",
      " [36.18546102 24.94491657  5.70523776 58.99725074 23.9936738  56.96673461\n",
      " 11.62803818 60.24328421 57.52479088 55.44323749]\n"
     ]
    }
   ],
   "source": [
    "y_hat = predict(X_train, wt_model)\n",
    "print('Predicted Labels are:\\n', y_hat[:10])\n",
    "print()\n",
    "print('Actual Labels are:\\n', y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used a random weight vector $\\textbf w$ here, most of the predicted labels do not match the actual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparision of vectorized and non-vectorized version of model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_vectorized_predict(X, w):\n",
    "    ''' Prediction of output label for a given input.\n",
    "\n",
    "        Args:\n",
    "            X: Feature matrix of shape (n,m+1)\n",
    "            w: weight vector of shape (m+1,n)\n",
    "        Returns: \n",
    "            y: Predicted label vector of shape(n,)\n",
    "    '''\n",
    "    y = []\n",
    "    for i in range(0, X.shape[0]):\n",
    "        y_hat_i = 0\n",
    "        for j in range(0, X.shape[1]):\n",
    "            y_hat_i += X[i][j]*w[j]\n",
    "        y.append(y_hat_i)\n",
    "    return np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_predict_non_vectorized (__main__.TestPredictNonVectorized) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1e70be336a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "class TestPredictNonVectorized(unittest.TestCase):\n",
    "    def test_predict_non_vectorized(self):\n",
    "\n",
    "        #set up\n",
    "        train_matrix = np.array([[1, 3, 2, 5], [1, 9, 4, 7]])\n",
    "        weight_vector = np.array([1, 1, 1, 1])\n",
    "        expected_label_vector = np.array([11, 21])\n",
    "\n",
    "        #call\n",
    "        predicted_label_vector = non_vectorized_predict(\n",
    "            train_matrix, weight_vector)\n",
    "\n",
    "        #asserts\n",
    "        #test the shape\n",
    "        self.assertEqual(predicted_label_vector.shape, (2,))\n",
    "\n",
    "        #and contents\n",
    "        np.testing.assert_array_equal(\n",
    "            expected_label_vector, predicted_label_vector)\n",
    "\n",
    "\n",
    "unittest.main(\n",
    "    argv=[''], defaultTest='TestPredictNonVectorized', verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing run time of vectorized and non-vectorized versions on dataset with 100 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time incurred in vectorized inference is: 0.0000000 s\n",
      "Total time incurred in non-vectorized inference is: 0.0000000 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "y_hat_vectorized = predict(X_train, w)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total time incurred in vectorized inference is: %0.7f s\" %\n",
    "      (end_time-start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "y_hat_non_vectorized = non_vectorized_predict(X_train, w)\n",
    "end_time = time.time()\n",
    "print(\"Total time incurred in non-vectorized inference is: %0.7f s\" %\n",
    "      (end_time - start_time))\n",
    "\n",
    "np.testing.assert_array_equal(y_hat_vectorized, y_hat_non_vectorized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing run time of vectorized and non-vectorized versions on large dataset of 1 million data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n=1000_000):\n",
    "    X = 10*np.random.rand(n)\n",
    "    X = add_dummy_feature(X)\n",
    "    noise = np.random.rand(n,)\n",
    "    y = X@w + noise\n",
    "    return X,y \n",
    "\n",
    "def preprocess(X,y):\n",
    "    X_train,y_train,X_test,y_test = train_test_split(X,y, test_size=0.2, random_state=42) \n",
    "    return X_train, y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time incurred in vectorized inference is : 0.002018 s\n",
      "Total time incurred in non-vectorized inference is: 1.079978 s\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_data(n=1000_000)\n",
    "X_train, y_train, X_test, y_test = preprocess(X, y)\n",
    "\n",
    "# Vectorized version\n",
    "start_time = time.time()\n",
    "y_hat_vectorized = predict(X_train, w)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total time incurred in vectorized inference is : %0.6f s\" %(end_time-start_time))\n",
    "\n",
    "# Non-vectorized version\n",
    "start_time = time.time()\n",
    "y_hat_non_vectorized = non_vectorized_predict(X_train, w)\n",
    "end_time = time.time()\n",
    "print('Total time incurred in non-vectorized inference is: %0.6f s' %(end_time-start_time))\n",
    "\n",
    "np.testing.assert_array_equal(y_hat_vectorized, y_hat_non_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the time required for non-vectorized inference in order of magnitude more than the vectorized inference."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32f02dc107888b055323539767db1f9cf579f03b0ed3a3ace7986ed2d38433ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
