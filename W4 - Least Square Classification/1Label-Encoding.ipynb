{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Least square classifier from scratch**\n",
    "\n",
    "We will implement least square classification from scratch in this notebook.\n",
    "\n",
    "*A few points to recall from the theory:*\n",
    "\n",
    "* Least square classification is used for estimating parameters of discriminant function from the given training data.\n",
    "\n",
    "* Least square classification adapts linear regression model for classification.\n",
    "\n",
    " * It uses **least square error** as a **loss funciton**\n",
    "\n",
    " * It uses **normal equation** method and **gradient descent** for estimating model parameters or weight vector.\n",
    "\n",
    "* Since it is a classification algorithm, we would use classification related evaluation metrics such as precision, recall, F-1 score ,AUC ROC/PR, and accuracy.\n",
    "\n",
    "*Additionally note that:*\n",
    "\n",
    "* We make use of polynomial feature transformation to obtain new features and then use that representation to learn non-linear decision boundaries between classes.\n",
    "\n",
    "\\begin{equation} \n",
    "y= w_0 + \\mathbf w^T \\phi\\mathbf(x) \n",
    "\\end{equation} \n",
    "\n",
    "            where, \n",
    "$ \\phi(\\mathbf x)$ is a polynomial feature transformation.\n",
    "\n",
    "* We can tackle issues of overfitting by using ridge or lasso regularizaiton just like linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Label encoding**\n",
    "\n",
    "Since the output $y$ is a discrete quantity, we use *one-hot encoding* to represent label. \n",
    "\n",
    "For a **binary classification :** \n",
    "* The label $0$ is represented with $[1,0]$, and \n",
    "\n",
    "* The label $1$ is represented with $[0,1]$.\n",
    "\n",
    "The same scheme is extended to the **multi-class setting**. In general for a $k$ class set up, we use one hot encoding in $k$ components vector. $[y_1,y_2,\\ldots, y_k]$ for label $1 \\le r \\le k, y_r$ would be 1 and other components would be 0.\n",
    "\n",
    "Concretely for a **three class classification set up :**\n",
    "* The label $0$ is represented with $[1,0,0]$\n",
    "\n",
    "* The label $1$ is represented with $[0,1,0]$\n",
    "\n",
    "* The label $2$ is represented with $[0,0,1]$\n",
    "\n",
    "In the following class, we implement LabelTransformer, that converts discrete labels into `one-hot-encoding`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelTransformer(object):\n",
    "    \"\"\" Label encoder decoder \n",
    "    Atrributes\n",
    "    ----------\n",
    "    n_classes : int \n",
    "        number of classes, K\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_classes: int = None):\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    @property\n",
    "    def n_classes(self):\n",
    "        return self.__n_classes\n",
    "\n",
    "    @n_classes.setter\n",
    "    def n_classes(self, K):\n",
    "        self.__n_classes = K\n",
    "        self.__encoder = None if K is None else np.eye(K)\n",
    "\n",
    "    @property\n",
    "    def encoder(self):\n",
    "        return self.__encoder\n",
    "\n",
    "    def encode(self, class_indices: np.ndarray):\n",
    "        \"\"\"\n",
    "        encode class index into one-of-k code \n",
    "        Parameters\n",
    "        ----------\n",
    "        class_indices : (N,) np.ndarray \n",
    "            non-negative class index \n",
    "            elements must be integer in [0, n_classes]\n",
    "\n",
    "\n",
    "        Returns : \n",
    "        -------\n",
    "        (N,K) np.ndarray \n",
    "            one-of-K encoding of input \n",
    "\n",
    "        \"\"\"\n",
    "        if self.n_classes is None:\n",
    "            self.n_classes = np.max(class_indices) + 1\n",
    "\n",
    "        return self.encoder[class_indices]\n",
    "\n",
    "    def decode(self, onehot: np.ndarray):\n",
    "        \"\"\"\n",
    "        decode one-of-k code into class index \n",
    "        parameters\n",
    "        ----------\n",
    "        onehot :(N,K) np.ndarray   \n",
    "        Returns:\n",
    "        -------\n",
    "        (N,) np.ndarray \n",
    "            class index \n",
    "        \"\"\"\n",
    "        return np.argmax(onehot, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Demonstration of LabelTransformer**\n",
    "##### 1. **Binary Classification setup** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_labels = LabelTransformer(2).encode(np.array([1, 0, 0, 1]))\n",
    "binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelTransformer().decode(binary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. **Multiclassification set up with three classes**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_labels = LabelTransformer(4).encode(np.array([1, 2, 3, 1]))\n",
    "multiclass_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelTransformer().decode(multiclass_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32f02dc107888b055323539767db1f9cf579f03b0ed3a3ace7986ed2d38433ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
