{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Artificial Neural Networks (ANN)**\n",
    "\n",
    "We begin by importing numpy and setting up a random number generator rng, with a seed value of 42. \n",
    "\n",
    "This seed value will be used throughout the notebook to ensure reproducability of experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Network Class**\n",
    "\n",
    "We shall start writing the network class. The two methods that are indispensable for any ML class are : \n",
    "\n",
    "* `fit` \n",
    "\n",
    "* `predict` \n",
    "\n",
    "Fitting a neural network model requires us to compute **two passes** on the data : \n",
    "\n",
    "1. **forward** propagation \n",
    "\n",
    "2. **backward** propagation \n",
    "\n",
    "We need to start at some place by initializing the network and various hyperparameters and this requires an `init` method. \n",
    "\n",
    "In most of these methods, we would have to take the help of certain helper functions : \n",
    "\n",
    "* **activation** function \n",
    "\n",
    "* **loss** function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is the process. But we will work through it in reverse order so that each step of the process doesn't have any forward references : \n",
    "\n",
    "**helpers --> init --> forward --> backward --> fit --> predict**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skeleton of the class is given in the code block that follows. \n",
    "\n",
    "For ease of of exposition, we are going to discuss the methods one at a time and then plug them into the class right at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network: \n",
    "    def init(self, layers, activation_choice = 'relu', output_choice='softmax', loss_choice='cce'):\n",
    "        pass \n",
    "\n",
    "    def forward(self, X):\n",
    "        pass \n",
    "\n",
    "    def backward(self, y,_y_hat):\n",
    "        pass \n",
    "\n",
    "    def fit(self, X,y, lr=0.01, epochs=100, batch_size=100):\n",
    "        pass\n",
    "\n",
    "    def predict(self,X): \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Activation Functions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Hidden Layers**\n",
    "\n",
    "We will look at two activation functions for the hidden layers. Both these functions will be applied function-wise. \n",
    "\n",
    "The input to these functions can **scalars, vectors or matrices**. \n",
    "\n",
    "1. **Sigmoid**\n",
    "\n",
    "\\begin{align}\n",
    "\\text {g}(z) = \\frac{1}{1 + e^{-z}}\n",
    "\\end{align}\n",
    "\n",
    "2. **Relu**\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text {g} (z)=\n",
    "    \\begin{cases}\n",
    "      z, \\text { $z$ $\\ge$ 0}\\\\\n",
    "      0, \\text { $z$ $<$ 0}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "We also need the derivatives of these functions while computing the backward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def grad_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def relu(z):\n",
    "    np.where(z>=0, z ,0)\n",
    "\n",
    "def grad_relu(z):\n",
    "    return np.where(z>=0 ,1,0)\n",
    "\n",
    "hidden_act = {'sigmoid':sigmoid, 'relu':relu}\n",
    "grad_hidden_act = {'sigmoid': grad_sigmoid, 'relu': grad_relu}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Output Layers**\n",
    "\n",
    "We will look at two activation functions for the **output layer** which are **identity for regression and softmax for classification**. \n",
    "\n",
    "\n",
    "1. **Identity** function (for **regression**)\n",
    "\n",
    "\\begin{align}\n",
    "\\text {g}(z) = \\text {z}\n",
    "\\end{align}\n",
    "\n",
    "2. **Softmax** function (for **classification**)\n",
    "\n",
    "\n",
    "The input to the softmax function will always be a matrix of size n X k, where k is the number of classes. Since we need a probablity distribution for each datapoint , the softmax will be computed row wise.\n",
    "\n",
    "\n",
    "\\begin{equation} \n",
    "\\text {softmax} \\textbf (Z) = \\frac{\\text {exp} \\textbf (Z)}{\\sum \\text {exp}(Z)}\n",
    "\\end{equation}\n",
    "\n",
    "To avoid overflow, we will subtract the row-wise maximum from each row while computing the softmax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(z):\n",
    "    return z \n",
    "\n",
    "def softmax(z):\n",
    "    # check if z is a matrix\n",
    "    assert z.ndim == 2\n",
    "\n",
    "    # to prevent overflow, subtract max, row-wise\n",
    "    z -= z.max(axis=1, keepdims = True)\n",
    "\n",
    "    # Compute rowwise softmax\n",
    "    prob = np.exp(z) / np.exp(z).sum(axis=1 ,keepdims = True)\n",
    "\n",
    "    # check if each row is a probablity distribution \n",
    "    assert np.allclose(prob.sum(axis=1), np.ones(z.shape[0]))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_act = {'softmax':softmax, 'identity':identity}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loss function**\n",
    "\n",
    "There are two types of losses we will use, **least square error for regression** and **categorical cross-entropy for classification**.\n",
    "\n",
    "1. **Least Square Error (LSE)**\n",
    "\n",
    "* **y** is a vector of target labels for *n* datapoints. \n",
    "\n",
    "* **ŷ** is the output of the network and corresponds to the predicted labels. \n",
    "\n",
    "\\begin{align}\n",
    "\\text{L} (y, ŷ) = \\frac{1}{2} (ŷ - y)^{\\intercal} (ŷ - y)\n",
    "\\end{align}\n",
    "\n",
    "2. **Categorical Cross-Entropy (CCE)**\n",
    "\n",
    "* **Y** is a matrix of target labels for *n* datapoints. \n",
    "\n",
    "* **Ŷ** is the output of the network and corresponds to the predicted labels. \n",
    "\n",
    "\\begin{align}\n",
    "\\text{L} (Y, Ŷ) = -1_{n}^T (\\text {Y} ⊙ \\text {log} \\text {Ŷ}) 1_k\n",
    "\\end{align}\n",
    "\n",
    "In our implementation, we will assume that the arguments to the loss function are always matrices of size **n X k**. \n",
    "\n",
    "In the case of regression, **k=1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square(y, y_hat):\n",
    "    return 0.5 * np.sum(np.transpose(y-y_hat) * (y-y_hat))\n",
    "\n",
    "def cce(Y, Y_hat):\n",
    "    return -np.sum(Y * np.log(Y_hat))\n",
    "\n",
    "losses = {'least_square':least_square , 'cce':cce}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initilization**\n",
    "\n",
    "Here we will look at two parts : \n",
    "\n",
    "* Network architechture \n",
    "\n",
    "* Weight Initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Network architechture**\n",
    "\n",
    "The following components mainly determine the structure of the network : \n",
    "\n",
    "* number of layers \n",
    "\n",
    "* number of neurons per layer \n",
    "\n",
    "We will use *l* to index the layers. The network has *L* layers in all. \n",
    "\n",
    "* *l* = 0 : **Input Layer** \n",
    "\n",
    "* 1 <= *l* <= *L*-1 : **Hidden Layers** \n",
    "\n",
    "* *l* = *L* : **Output Layer** \n",
    "\n",
    "We shall represent the number of layers and the neurons using a list layers. The variable *L* will never make an explicit appearance anywhere, instead we will use **range(len(layers))** to iterate  through the layers.\n",
    "\n",
    "One useful task is to **compute the total number of parameters in the network**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(layers):\n",
    "    num_params = 0 \n",
    "    for l in range(1 ,len(layers)): \n",
    "        num_weights = layers[l-1] * layers[l]\n",
    "        num_biases = layers[l]\n",
    "        num_params += (num_weights + num_biases)\n",
    "    return num_params\n",
    "\n",
    "# Test count_params \n",
    "assert count_params([64,5,10]) == (64 * 5 + 5) + (5 * 10 + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parameter initialization**\n",
    "\n",
    "The weight-matrix at layer *l* has a size of `layers[l - 1]` X `layers[l]`.\n",
    "\n",
    "The bias at layer *l* has a size of `layers[l]`.\n",
    "\n",
    "We will store all these weights in a list `w` of the same size as `layers`. `W[l]` would correspond to **W_l**.\n",
    "\n",
    "Since there are *L* weight matrices, W[0] would be set to `None`. Recall that the size of the list is `L+1`. A similar list wolud be required for `b`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the gradient descent update simpler, it will be useful to have a **master vector, θ**, that has a reference to all the parameters in the network. \n",
    "\n",
    "We will do the same for the **gradient θ(x)**. So, **whenever θ is updated, the weights W1 will also be updated** and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do this is to **first start with the master vector and then reshape chunks of it into the dimensions of a weight matrix**. \n",
    "\n",
    "Reshaping an array usually returns a view of an array and not a copy. \n",
    "\n",
    "To understand this function better, refer to Numpy's documentation on \"[**Copies and Views**](https://numpy.org/doc/stable/user/basics.copies.html)\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layers):\n",
    "    # number of params in the n/w\n",
    "    num_params = count_params(layers)\n",
    "\n",
    "    # weights\n",
    "    W = [None for _ in range(len(layers))]\n",
    "    # biases    \n",
    "    b = [None for _ in range(len(layers))]\n",
    "    # gradient loss w.r.t weights    \n",
    "    gW = [None for _ in range(len(layers))]\n",
    "    # gradient loss w.r.t biases\n",
    "    gb = [None for _ in range(len(layers))]\n",
    "\n",
    "    # sample from N(0,1) to initialize the params \n",
    "    theta = rng.standard_normal(num_params)\n",
    "    g_theta = np.zeros(num_params)\n",
    "\n",
    "    # (start, end) specify the portion of theta that corresponds to the prameter W_l and b_l. \n",
    "    start, end = 0 ,0\n",
    "    for l in range(1, len(layers)):\n",
    "        # reshape the section (start, end) and assign it to W[l]\n",
    "        end = start + layers[l-1] * layers[l]\n",
    "        W[l] = theta[start:end].reshape(layers[l-1], layers[l])\n",
    "        gW[l] = g_theta[start:end].reshape(layers[l-1], layers[l])\n",
    "\n",
    "        # reshape the section (start, end) and assign it to b[l]\n",
    "        start, end = end, end + layers[l]\n",
    "        b[l] = theta[start:end].reshape(layers[l])\n",
    "        gb[l] = g_theta[start:end].reshape(layers[l])\n",
    "        start = end\n",
    "\n",
    "    return theta, g_theta, W, b, gW, gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test init params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64, 32, 10]\n",
    "params = init_params([64, 32, 10])\n",
    "for l in range(1, len(layers)):\n",
    "    # check if the weights are views of the master vector \n",
    "    assert params[2][1].base is params[0]\n",
    "    assert params[3][1].base is params[0]\n",
    "    assert params[4][1].base is params[1]\n",
    "    assert params[5][1].base is params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to initialize the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(self, layers, activation_choice='relu', output_choice='softmax',loss_choice='cce'):\n",
    "    self.layers = layers \n",
    "\n",
    "    # Parameters and gradients \n",
    "    self.theta, self.g_theta, \\\n",
    "    self.W, self.b, \\\n",
    "    self.gW, self.gb = init_params(layers)\n",
    "\n",
    "    #activation functions \n",
    "    self.ghid = hidden_act[activation_choice]\n",
    "    self.grad_ghid = grad_hidden_act[activation_choice]\n",
    "    self.gout = output_act[output_choice]\n",
    "\n",
    "    # loss \n",
    "    self.loss = losses[loss_choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Forward Pass**\n",
    "\n",
    "The forward algorithm is as follows : \n",
    "\n",
    "First we initialize **$A_0$ = $X$**. Then, we iteratively compute the pre activations and the activations for every layer $l$ using the equations given below : \n",
    "\n",
    "\\begin{align}\n",
    "Z_1 = A_{l-1}W_1 + b_1\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "A_l = g(Z_1)\n",
    "\\end{align}\n",
    "\n",
    "Finally the network's output is given by : $ŷ$ = $A_L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self,X):\n",
    "    self.z = [None for _ in range(len(self.layers))]\n",
    "    self.A = [None for _ in range(len(self.layers))]\n",
    "    self.A[0] = X\n",
    "    self.z[0] = X\n",
    "\n",
    "    for l in range(1, len(self.layers)):\n",
    "        self.z[l] = self.A[l - 1] @ self.W[l] + self.b[l]\n",
    "        self.A[l] = self.ghid(self.z[l])\n",
    "\n",
    "    self.A[-1] = self.gout(self.z[-1])\n",
    "    return self.A[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Backward Pass**\n",
    "\n",
    "The backward pass algorithm is as follows : \n",
    "\n",
    "We first initialize the gradients of the pre-activation at layer $L$ as $Z_L^{(g)}$ = $Ŷ$ - $Y$.\n",
    "\n",
    "It is fortunate that this true for both regression and classification. \n",
    "\n",
    "The other gradients can be iteratively updated using these equations. \n",
    "\n",
    "\\begin{align}\n",
    "W_l^{(g)} = A_{l-1}^{\\intercal} . Z_l^{(g)}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "b_l^{(g)} = {Z_l^{(g)}}^{\\intercal} 1_a\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "A_{l - 1}^{(g)} = Z_{l}^{(g)} .{ W_l}^{\\intercal}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "Z_{l - 1}^{(g)} = A_{l - 1}^{(g)} ⊙ g' (Z_{l - 1})\n",
    "\\end{align}\n",
    "\n",
    "An important point to note is the use of `self.gW[l][:, :]` , while updating the gradient of the weights and not `self.gW[l] . self.gW[l][:, :] ` does an in-place update, thus maintaining a link with the master params, namely `self.theta`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, Y, Y_hat):\n",
    "    gZ = [None for _ in range(len(self.layers))]\n",
    "    gA= [None for _ in range(len(self.layers))]\n",
    "    gZ[-1] = Y_hat - Y\n",
    "\n",
    "    for l in range(len(self.layers) - 1, 0, -1):\n",
    "        self.gW[l][:, :] = self.A[l - 1].T @ gZ[l]\n",
    "        self.gb[l][:] = np.sum(gZ[l].T, axis=1)\n",
    "        gA[l - 1] = gZ[l] @ self.W[l].T\n",
    "        gZ[l - 1] = gA[l - 1] * self.grad_ghid(self.z[l - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fit**\n",
    "\n",
    "We now have all the ingredient sto fit a model using gradient descent. We will use **mini-batch gradient descent**. \n",
    "\n",
    "The **batch size**, **learning rate** and the **number of epochs** will be the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X,Y,lr=0.01, epochs=100, batch_size=100):\n",
    "    self.losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # compute loss \n",
    "        Y_hat = self.forward(X)\n",
    "        self.losses.append(self.loss(Y, Y_hat))\n",
    "\n",
    "        # shuffle the dataset \n",
    "        indices = np.arange(X.shape[0])\n",
    "\n",
    "        # use rng.shuffle to maintain reproductability \n",
    "        rng.shuffle(indices)\n",
    "        X, Y = X[indices], Y[indices]\n",
    "\n",
    "        # number of batches \n",
    "        num_batches = X.shape[0] // batch_size \n",
    "\n",
    "        # mini batch GD \n",
    "        for b in range(num_batches):\n",
    "            Xb = X[b * batch_size: (b + 1) * batch_size]\n",
    "            Yb = Y[b * batch_size: (b + 1) * batch_size]\n",
    "\n",
    "            # compute the predictions for this batch \n",
    "            Y_hat_b = self.forward(Xb)\n",
    "            # compute the gradients for this batch \n",
    "            self.backward(Yb, Y_hat_b)\n",
    "            # update the gradients of all parameters \n",
    "            # -= is used for in-place update \n",
    "            self.theta -= lr * self.g_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Predict**\n",
    "\n",
    "Finally, we can use a trained model to predict the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    Y_hat = self.forward(X)\n",
    "    # for regression \n",
    "    if X.shape[-1] == 1:\n",
    "        return Y_hat\n",
    "    # for classification \n",
    "    else : \n",
    "        return np.argmax(Y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plugging in all functionalities**\n",
    "\n",
    "We can now plug all of this into our class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network.__init__ = init \n",
    "Network.forward = forward \n",
    "Network.backward = backward \n",
    "Network.fit = fit \n",
    "Network.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dealing with Data**\n",
    "\n",
    "We will import the digits dataset from `sklearn` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8), (1797,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = digits.images\n",
    "y = digits.target\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Normalize the data so that all features lie in (0,1).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= np.max(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plotting the images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0])\n",
    "plt.title(f'Sample image with label {y[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Reshaping Input.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(-1, 64)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size\n",
    "isize = X.shape[-1]\n",
    "# output size\n",
    "osize = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Dealing with one hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(y):\n",
    "    k = len(np.unique(y))\n",
    "    return np.eye(k)[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1078, 64) (1078, 10)\n",
      "Testing data shape :  (719, 64) (719, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "y_train = one_hot_encoder(y_train)\n",
    "y_test = one_hot_encoder(y_test)\n",
    "\n",
    "print('Training data shape : ', X_train.shape, y_train.shape)\n",
    "print('Testing data shape : ', X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Applying Fit method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [isize, 32, osize]\n",
    "network = Network(layers, activation_choice='sigmoid', output_choice='softmax',loss_choice='cce')\n",
    "\n",
    "# fit the network on the data \n",
    "epochs = 50 \n",
    "network.fit(X_train, y_train, lr=0.01, epochs=epochs, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Plotting the losses.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(range(epochs), network.losses)\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('CCE Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Computing the accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size = 719\n",
      "Number of parameters = 2410\n"
     ]
    }
   ],
   "source": [
    "print(f'Test data size = {X_test.shape[0]}')\n",
    "print(f'Number of parameters = {count_params(layers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.00\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(network.predict(X_test) == y_test) / X_test.shape[0] * 100\n",
    "print(f'Accuracy = {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32f02dc107888b055323539767db1f9cf579f03b0ed3a3ace7986ed2d38433ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
